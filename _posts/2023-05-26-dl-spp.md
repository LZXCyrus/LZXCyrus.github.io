---
layout: post
title:  "本科生涯大数据竞赛的感想：浅尝辄止、意犹未尽与翻车"
date:   2023-06-10
excerpt: ""
tag:
- notes
---

<br/>

## 1 哪里去找大数据竞赛

### 1.1 一些含金量比较高的竞赛网站

Lack of high-quality labeled data stands in the way of conventional supervised learning methods. Instead, we approach this problem using semi-supervised learning with a large language model (LLM). This paper generates weak financial sentiment labels for Reddit posts with an LLM and then uses that data to train a small model that can be served in production. Prompting the LLM to produce Chain-of-Thought summaries and forcing it through several reasoning paths helps generate more stable and accurate labels, while using a regression loss further improves distillation quality. With only a handful of prompts, the final model performs on par with existing supervised models. **Though production applications of THE model are limited by ethical considerations**, the model’s competitive performance points to the great potential of using LLMs for tasks that otherwise require skill-intensive annotation.


> Overall pipeline (a), and prompt design for in-context learning (b)
